{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatsukikoga/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 基本のライブラリを読み込む\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# グラフ描画\n",
    "from matplotlib import pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# グラフを横長にする\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6\n",
    "\n",
    "from fbprophet import Prophet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "import xgboost as xgb\n",
    "\n",
    "import sys,os\n",
    "sys.path.append(os.pardir)\n",
    "from DataReader import DataReader\n",
    "dr = DataReader()\n",
    "train_df, test_df = dr.get_raw_data()\n",
    "\n",
    "def score(y_pred, y):\n",
    "    abs_list = [abs(y_pred_ - y_) for (y_pred_, y_) in zip(y_pred, y)]\n",
    "    return sum(abs_list) / len(abs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatsukikoga/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "INFO:fbprophet.forecaster:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
     ]
    }
   ],
   "source": [
    "# timeseries は特性上混ぜるだけ(no Cross Validation)\n",
    "df = train_df[[\"datetime\", \"y\"]]\n",
    "df[\"ds\"] = pd.to_datetime(df.datetime)\n",
    "df = df.drop(\"datetime\", axis=1)\n",
    "df = df.reset_index()\n",
    "\n",
    "event_df_train = pd.DataFrame({\n",
    "  'holiday': 'client_train',\n",
    "  'ds': train_df[train_df.client == 1].datetime,\n",
    "})\n",
    "event_df_test = pd.DataFrame({\n",
    "  'holiday': 'client_test',\n",
    "  'ds': test_df[test_df.client == 1].datetime,\n",
    "})\n",
    "\n",
    "event_df = pd.concat((event_df_train, event_df_test))\n",
    "\n",
    "def march_weekend(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.weekday() >= 5 and date.month == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['march_weekend'] = df['ds'].apply(march_weekend)\n",
    "\n",
    "m = Prophet(weekly_seasonality=True, yearly_seasonality=True, holidays=event_df)\n",
    "m.add_seasonality(name='monthly', period=30.5, fourier_order=5, prior_scale=10)\n",
    "m.add_regressor('march_weekend', prior_scale=50)\n",
    "\n",
    "m.fit(df)  # df is a pandas.DataFrame with 'y' and 'ds' columns\n",
    "future = m.make_future_dataframe(periods=365)\n",
    "future['march_weekend'] = future['ds'].apply(march_weekend)\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regressor(train_idx, test_idx):\n",
    "    train, test = dr.get_dummied_data()\n",
    "    X = train.drop(\"y\", axis=1).as_matrix()\n",
    "    y = train.y.as_matrix()\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X_train, y_train)\n",
    "    print(regr.predict(X_test).shape)\n",
    "    return regr.predict(X_test), regr.predict(test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,BatchNormalization\n",
    "\n",
    "def neural(train_idx, test_idx):\n",
    "    train, test = dr.get_dummied_data()\n",
    "    X = train.drop(\"y\", axis=1).as_matrix()\n",
    "    y = train.y.as_matrix()\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    model = Sequential()\n",
    "    # 73, 62\n",
    "    model.add(Dense(140,input_dim=55,activation=keras.layers.advanced_activations.LeakyReLU(alpha=0.3)))\n",
    "    model.add(Dense(70,input_dim=55,activation=keras.layers.advanced_activations.LeakyReLU(alpha=0.3)))\n",
    "    model.add(Dense(1))\n",
    "    opt = keras.optimizers.Adam(lr = 0.05,beta_1=0.9,beta_2=0.999,epsilon=1e-08,decay=0.0003)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss = \"mean_absolute_error\",\n",
    "                  metrics=[\"mae\"])\n",
    "    model.fit(X_train,y_train,nb_epoch=100)\n",
    "    return model.predict(X_test)[:,0], model.predict(test.as_matrix())[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svr_rbf(train_idx, test_idx):\n",
    "    train, test = dr.get_dummied_data()\n",
    "    X = train.drop(\"y\", axis=1).as_matrix()\n",
    "    y = train.y.as_matrix()\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    model = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.predict(X_test), model.predict(test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svr_lin(train_idx, test_idx):\n",
    "    train, test = dr.get_dummied_data()\n",
    "    X = train.drop(\"y\", axis=1).as_matrix()\n",
    "    y = train.y.as_matrix()\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    model = SVR(kernel='linear', C=1e3)\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.predict(X_test), model.predict(test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svr_poly(train_idx, test_idx):\n",
    "    train, test = dr.get_dummied_data()\n",
    "    X = train.drop(\"y\", axis=1).as_matrix()\n",
    "    y = train.y.as_matrix()\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    model = SVR(kernel='poly', C=1e3, degree=3)\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.predict(X_test), model.predict(test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xg_boost(train_idx, test_idx):\n",
    "    train, test = dr.get_data()\n",
    "    X = train.drop(\"y\", axis=1).as_matrix()\n",
    "    y = train.y.as_matrix()\n",
    "    X_train = X[train_idx]\n",
    "    y_train = y[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    model = xgb.XGBRegressor(max_depth =30,n_estimators=500)\n",
    "    model.fit(X_train,y_train)\n",
    "    return model.predict(X_test), model.predict(test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tatsukikoga/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/sklearn/cross_validation.py:552: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressor:  0\n",
      "fold:  0\n",
      "(735,)\n",
      "fold:  1\n",
      "(698,)\n",
      "fold:  2\n",
      "(668,)\n",
      "regressor:  1\n",
      "fold:  0\n",
      "fold:  1\n",
      "fold:  2\n",
      "regressor:  2\n",
      "fold:  0\n"
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "skf = list(StratifiedKFold(train_df[\"y\"], n_folds))\n",
    "regressors = [linear_regressor, xg_boost, neural]\n",
    "dataset_blend_train = np.zeros((len(train_df), len(regressors)+1))\n",
    "dataset_blend_test = np.zeros((len(test_df), len(regressors)+1))\n",
    "\n",
    "# stage 1\n",
    "for j, regressor in enumerate(regressors):\n",
    "    print('regressor: ', j)\n",
    "    dataset_blend_test_j = np.zeros((len(test_df), len(skf)))\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print('fold: ', i)\n",
    "        (dataset_blend_train[test, j], dataset_blend_test_j[:, i]) = regressor(train, test)\n",
    "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
    "\n",
    "# prophet の予測データをマージ\n",
    "dataset_blend_train[:, len(regressors)] = forecast[\"yhat\"][:-365]\n",
    "dataset_blend_test[:, len(regressors)] = forecast[\"yhat\"][-365:]\n",
    "\n",
    "# stage 2\n",
    "model = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "model.fit(dataset_blend_train, train_df[\"y\"])\n",
    "y_submission = model.predict(dataset_blend_test)\n",
    "y_pred = model.predict(dataset_blend_train)\n",
    "\n",
    "score(y_pred, train_df[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = pd.DataFrame(y_submission, columns=['y'])\n",
    "from DataWriter import DataWriter\n",
    "dw = DataWriter()\n",
    "dw.write_csv(ans)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
